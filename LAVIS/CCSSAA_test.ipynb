{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ab8e4d-7302-4246-963b-f250cb3be95e",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "id": "f582fa54-f444-4db8-a324-10e11a8d6133",
   "metadata": {},
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from lavis.models import load_model_and_preprocess\n",
    "model, vis_processors, _ = load_model_and_preprocess(\n",
    "    name=\"blip_caption\", model_type=\"large_coco\", is_eval=True, device=device\n",
    ")\n",
    "\n",
    "import openai\n",
    "openai.api_key = 'use-your-own-api-key'\n",
    "\n",
    "import os\n",
    "import replicate\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = 'use-your-own-api-key'\n",
    "\n",
    "from requests import get\n",
    "import string\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb46233e-da26-4449-8862-839861a343ac",
   "metadata": {},
   "source": [
    "# Get Several Captions about Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aad17f-b09d-487b-907d-c5ea0d1365f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captions(location, num_captions):\n",
    "    raw_image = Image.open(location).convert(\"RGB\")\n",
    "    display(raw_image.resize((596, 437)))\n",
    "    image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "    captions = model.generate({\"image\": image}, use_nucleus_sampling=True, num_captions=num_captions)\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845483e-32d8-41cb-acd7-fc04fc3e0649",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get a Compressed Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94384f7e-ae2f-45a5-b628-89f244d58563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(captions):\n",
    "    initial_msg = \"I'm doing Image captioning with deep learning model. If I feed the model a image, it gives me several sentences. But I can't fully trust the model. So if i give you the sentences, read them and give me a compressed sentence. Not just adding. I don't need any description. I just want a 'compressed' sentence. I'll try this many time.\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': initial_msg},\n",
    "    ]\n",
    "    \n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    messages.append({\n",
    "        'role': 'assistant',\n",
    "        'content': res['choices'][0]['message']['content']\n",
    "    })\n",
    "    \n",
    "    messages.append({\n",
    "        'role': 'user',\n",
    "        'content': ' '.join(captions)\n",
    "    })\n",
    "    \n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    messages.append({\n",
    "        'role': 'assistant',\n",
    "        'content': res['choices'][0]['message']['content']\n",
    "    })\n",
    "    \n",
    "    res = res['choices'][0]['message']['content']\n",
    "\n",
    "    try:\n",
    "        sentence = res.split(':')[1].replace('\\n', ' ').replace(\"'\", \"\").replace('\"','').strip()\n",
    "    except:\n",
    "        sentence = res.replace('\\n', ' ').replace(\"'\", \"\").replace('\"','').strip()\n",
    "        \n",
    "    print(\"Compressed Sentence: \" + sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2f4fe-3ddc-4916-ae4f-79080cf693f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da252a18-fdf1-498f-b2cc-2c5b052a7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(sentence):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '[' + sentence + ']' + 'Recommend me three music genres that go well with this sentence. Seperate genres in comma. Just print genres. No discription. No number.'}\n",
    "    ]\n",
    "    \n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    res = res['choices'][0]['message']['content']\n",
    "\n",
    "    try:\n",
    "        genre = res.split(':')[1].replace('\\n', ' ').replace(\"'\", \"\").replace('\"','').strip()\n",
    "    except:\n",
    "        genre = res.replace('\\n', ' ').replace(\"'\", \"\").replace('\"','').strip()\n",
    "\n",
    "    genres = genre.split(\", \")\n",
    "    sentence_with_genre = [sentence + \", Genre: \" + genre for genre in genres]\n",
    "    for i in sentence_with_genre:\n",
    "        print(i)\n",
    "        \n",
    "    return sentence_with_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dfe92b-f68a-48c3-a72a-0449df204ade",
   "metadata": {},
   "source": [
    "# Combine Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b7c4e-37f2-4106-8d9b-38d9df327f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2txt(location=\"./docs/_static/merlion.png\", num_captions=3):\n",
    "    captions = get_captions(location, num_captions)\n",
    "    sentence = get_sentence(captions)\n",
    "    sentence_with_genre = get_genres(sentence)\n",
    "    return sentence_with_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017837d1-5418-44a7-99eb-9697b1c1a545",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate Random String for File Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36dbc2-e0b7-4302-97f4-dc9dbdd7dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string():\n",
    "    characters = string.ascii_lowercase + string.ascii_uppercase + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for _ in range(16))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fa88c-5011-4dd1-951d-5e1760dbc3a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e43232-63a6-4abb-b8c4-656495a71205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url):\n",
    "    if not os.path.exists('./audio'):\n",
    "        os.makedirs('./audio')\n",
    "    path = './audio/' + generate_random_string() + '.wav'\n",
    "    with open(path, \"wb\") as file:\n",
    "        response = get(url)\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89a344-8446-466b-aa9c-317404c95bf6",
   "metadata": {},
   "source": [
    "# Get Musics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63367a-9e83-4143-ba2d-6b68f99e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_musics(location=\"./docs/_static/tent.jpg\", num_captions=3):\n",
    "    sentence_with_genre = img2txt(location, num_captions=3)\n",
    "    output = [replicate.run(\n",
    "        \"riffusion api key\",\n",
    "        input={\"prompt_a\": prompt_a}\n",
    "    )['audio'] for prompt_a in sentence_with_genre]\n",
    "\n",
    "    for i, out in enumerate(output):\n",
    "        print(str(i+1) + \".\" + out)\n",
    "        download(out)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ebf5c1-7f59-4a1d-90f1-6a8a8753ab30",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86620b-9bfe-458d-acac-4ca248040964",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"./docs/_static/merlion.png\"\n",
    "num_captions = 3\n",
    "output = get_musics(location, num_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95cefd-cd47-4adb-b271-bfd748e93d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAVIS",
   "language": "python",
   "name": "lavis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
